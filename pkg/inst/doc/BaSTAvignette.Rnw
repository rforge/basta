% -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
\documentclass[a4paper]{article}
\title{\textbf{BaSTA}\\an R package for Bayesian estimation of age-specific mortality from incomplete mark-recapture/recovery data with covariates}
\date{}
\author{Fernando Colchero, Owen R. Jones and Maren Rebke\\
{\emph{Max Planck Institute for Demographic Research}}\\
}

% Import packages %
\usepackage{amsmath}
\usepackage{amscd}
\usepackage[tableposition=top]{caption}
\usepackage{ifthen}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{multirow}
\usepackage{color}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{array}
\usepackage{longtable}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{array}
\usepackage{caption}
\captionsetup{margin=20pt,font=small,labelfont=bf}
\makeindex

% \SweaveOpts{keep.source=TRUE, echo=TRUE}
%\VignetteIndexEntry{BaSTA}

% General set up commands %
\linespread{1.3}
\geometry{a4paper, textwidth=15cm, textheight=25cm}
%\addtolength{\hoffset}{-0.5in}
%\addtolength{\voffset}{-0.5in}
%\addtolength{\textheight}{1in}
%\addtolength{\textwidth}{1in}

\bibpunct{(}{)}{,}{a}{}{;}

\newcommand{\linen}[1]{(line {\color{red} \small{\texttt{#1}}})}
\newcommand{\linento}[2]{(lines {\color{red} \small{\texttt{#1}}} to {\color{red} \small{\texttt{#2}}})}
\newcommand{\mverb}[1]{\texttt{\textbf{#1}}}
%\renewcommand{\arraystretch}{2}
\newcommand{\bth}{\boldsymbol{\theta}}
\newcommand{\bal}{\boldsymbol{\alpha}}
\newcommand{\bbe}{\boldsymbol{\beta}}
\newcommand{\bet}{\boldsymbol{\eta}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\ba}{\mathbf{a}}

\begin{document}
\maketitle
\tableofcontents
\section{Introduction}


Here we present BaSTA (Bayesian Survival Trajectory Analysis), a free-open-source R package \citep{R} that implements the hierarchical Bayesian model described by \cite{ColcheroClark2011}.  This package facilitates drawing inference on age-specific mortality from CRR data when a large proportion (or all) of the records have missing information on times of birth and death. In addition, BaSTA allows to evaluate the effect of continuous and categorical covariates on mortality. 

<<setup, print=FALSE, echo=FALSE>>=
library(BaSTA)
data("basta.dat", package = "BaSTA")
data("basta.out", package = "BaSTA")
@

\begin{figure}[h!]
  \label{Fig1}
  \begin{center}
    \includegraphics[width=8cm]{Fig4}
  \caption{Work flow of BaSTA's main function \mverb{basta()} after data input and argument definition from the user. During the initial ``Error check'' sequence, 1 implies that no errors were detected and 0 means otherwise. In the later case, the function is stopped and an error message is printed explaining the error and suggesting solutions.}
  \end{center}
\end{figure}

BaSTA consists of a set of routines initialized by the user through data input and the definition of basic model settings (Fig. \ref{Fig1}). The package then verifies that the data has the right format and that the user-defined model settings are consistent (i.e. initial error checks). If no errors are found, the model runs one or multiple Monte Carlo Markov Chain (MCMC) algorithms (for a full description of the algorithm see \citealt{ColcheroClark2011}). After the MCMC runs are finished, the package calculates a range of diagnostics that include measures of serial autocorrelation on parameter traces, parameter update rates, convergence and preliminary model selection.

The package's main function, called \mverb{basta()}, defines its own S3 method \citep{ChambersHastie92} and outputs an object of class \mverb{basta} which can then be explored with the generic functions \mverb{plot()}, \mverb{summary()} and \mverb{print()}. The package also includes two data formatting functions, \mverb{CensusToCaptHist()} and \mverb{MakeCovMat()}, and a data checking function \mverb{DataCheck()}. 

\section{Data formatting}
The input data for BaSTA uses a format compatible with other programs that deal with CRR data sets such as MARK \citep{White&Burnham99}. The data needs to be configured as a table in data frame format where each row corresponds to one individual.  The first column corresponds to the individual ids while the second and third columns include the years of birth and death, respectively. Next, $T$ columns ($T =$ study span), one per study year, are filled with the individual recapture histories. Thus, every year an individual is detected the corresponding column is filled with 1 and 0 otherwise. In case covariates are to be included, additional columns can be added, one per covariate. For instance, table \ref{Tab1} shows a data frame for four individuals and a study span of $T = 4$ years with one covariate, i.e. location. In this example, individuals 1 and 2 have known birth year and individuals 1 and 3 have know death year, individual 1 was detected in the first, third and fourth year of the study, individual 2 from the second to the forth year and so forth. Individuals 1 and 2 belong to location 1 and individuals 3 and 4 to location 2.

\begin{table}[h]
  \caption{Data format required by BaSTA.}
  \label{Tab1}
  \begin{center}
\begin{tabular}{c|cc|cccc|c}
ID&Birth&Death&year 1&year 2&year 3&year 4&location\\
\hline
1 & $b_1$ & $d_1$ & 1 & 0 & 1 & 1&loc 1\\
2 & $b_2$ & 0  & 0 & 1 & 1 & 1&loc 1\\
3 & 0 & $d_3$ & 1 & 1 & 1 & 1&loc 2\\
4 & 0 & 0  & 0 & 1 & 1 & 0&loc 2\\
\hline
\end{tabular}
  \end{center}
\end{table}

\subsection{Construct capture history matrix: \mverb{CensusToCaptHist()}}
This matrix can be constructed using BaSTA's built-in data formatting functions. For instance, with function \mverb{CensusToCaptHist()}, it is possible to convert a conventional individual survey table (i.e. one record per time an individual is observed) to the recapture matrix described above. Below is an example with simulated data where we simulate the capture history of five individuals between 1990 and 2000:
<<>>=
id.vec     <- sort(sample(1:5, size = 15, replace = TRUE))
d.vec       <- rep(0, length(id.vec))
for(i in unique(id.vec)){
  svec     <- which(id.vec == i)
  d.vec[svec] <- sort(sample(1990:2000, length(svec)))
}
Y            <- CensusToCaptHist(ID = id.vec,  d = d.vec, dformat = "yyyy")
@
Argument \mverb{ID} in function \mverb{CensusToCaptHist} takes a vector with the individual ids, argument \mverb{d} the dates in which each individual was detected and \mverb{dformat} is used to specify the date format in \mverb{d}.
The resulting capture history matrix looks like:
<<print=FALSE, echo=FALSE>>=
print(Y)
@


\subsection{Construct covariates matrix: \mverb{MakeCovMat()}}
Covariates can be set up in the apropriate format with function \mverb{MakeCovMat()}. Below is an example with simulated data for five individuals:
<<>>=
sex        <- sample(c("f", "m"), 5, replace = TRUE)
weight     <- rnorm(5, mean = 10, sd = 1)
raw.mat    <- data.frame(sex, weight)
@

This covariate data frame looks like:
<<print=FALSE,echo=FALSE>>=
print(raw.mat)
@

The data frame \mverb{raw.mat} contains a column for the sex categorical covariate and one for the weight covariate. This data frame can be then rearranged with function \mverb{MakeCovMat()} so that it can be incorporated into the main data frame for BaSTA: 
<<>>=
cov.mat    <- MakeCovMat(x = c("sex", "weight"), data = raw.mat)
@

\noindent which produces the following matrix:
<<print=FALSE,echo=FALSE>>=
print(cov.mat)
@

Argument \mverb{x} can be used to specify which covariates should be included in the covariate matrix either with a character string vector (see example above), or with a numerical vector that indicates the column numbers in the data frame \mverb{data} that should be used for inference. In case all the columns are to be included, argument \mverb{x} can be ignored and only argument \mverb{data} needs to be specified. Alternatively, \mverb{x} can be of class \mverb{formula}, as we show in the following example:
<<>>=
cov.mat    <- MakeCovMat(x = ~ sex + weight + sex:weight, data = raw.mat)
@

\noindent which produces the following matrix:
<<print=FALSE,echo=FALSE>>=
print(cov.mat)
@

In this case, we are including an interaction between sex and weight. For further details on how to specify a formula in R, type \mverb{help(formula)} in the R console. 

\subsection{Verify data consistency: \mverb{DataCheck()}}
After the final data frame is constructed, it can be verified with function \mverb{DataCheck()}. This function performs a range of diagnostics on the data frame (Table \ref{Tab2}). Below is an example with the built in dataset:
<<eval=FALSE>>=
## Load data:
data("basta.dat", package = "BaSTA")

## Check data consistency:
new.dat  <- DataCheck(basta.dat, studyStart = 51, 
            studyEnd = 70, autofix = rep(1,7), silent = FALSE)
@

If argument \mverb{silent} is set as \mverb{FALSE}, then the function prints out a range of descriptive statistics about the dataset as folows:
<<print=FALSE, echo=FALSE,eval=TRUE>>=
new.dat  <- DataCheck(basta.dat, studyStart = 51, 
            studyEnd = 70, autofix = rep(1,7), silent = FALSE)
@

Data check searches the dataset for seven different types of error (Table \ref{Tab2}), which can be fixed using argument \mverb{autofix}. Although this can save a lot of time and effort to the user, we strongly advise to verify the reported errors and make an informed decision on how to fixed them. 

\begin{table}[h!]
  \caption{Description of error types in datasets as defined in function \mverb{DataCheck} and the actions that are taken based on the values provided in argument \mverb{autofix}.}
  \label{Tab2}
  \begin{center}
\begin{tabular}{p{2cm}p{4cm}p{7cm}}
\hline
\textbf{Error type}&\textbf{Description}&\textbf{autofix code}\\
\hline\hline
  \textbf{type 1} & Deaths occurring before the study starts& 0 = do nothing; 1 = remove from dataframe\\
  \textbf{type 2} & No birth/death AND no recaptures& 0 = do nothing; 1 = remove from dataframe\\
  \textbf{type 3} & Births recorded after death& 0 = do nothing; 1 = replace death records with 0; 2 = replace birth records with 0; 3 = replace both birth and death records with 0\\
  \textbf{type 4} &Recaptures after death& 0 = do nothing; 1 = remove spurious post-death observations\\
  \textbf{type 5} & Recaptures before birth. & 0 = do nothing; 1 = remove observations that pre-date year of birth \\
  \textbf{type 6} & Year of birth is not a zero in the recapture matrix& 0 = do nothing; 1 = replace birth year element of observation matrix with 0\\
  \textbf{type 7} &Year of death is not a zero in the recapture matrix& 0 = do nothing; 1 = replace death year element of observation matrix with 0\\
\hline
\end{tabular}
  \end{center}
\end{table}

As an example, below we show how \mverb{DataCheck} reports errors for a dataset that has death years before the birth years (i.e. \textbf{type 3} error) for a few individuals:
<<print=FALSE, echo=FALSE,eval=TRUE>>=
dat.error  <- basta.dat
id        <- sapply(c(55, 60, 65), function(x) which(basta.dat[, 2] == x)[1])
dat.error[id, 3] <- dat.error[id, 2] - c(1, 2, 4)
@

<<eval=TRUE>>=
new.dat  <- DataCheck(dat.error, studyStart = 51, 
            studyEnd = 70, autofix = rep(1,7), silent = TRUE)
@

\section{Setting up the analysis: function \mverb{basta()}}
After the data has been formatted and verified for consistency the analysis is performed with function \mverb{basta()}. In this section we explain the arguments used in this function. This function can be ran by specifying only the dataset with argument \mverb{object} and the times of start and end of the study with arguments \mverb{studyStart} and \mverb{studyEnd}, respectively. Thus, a simple analysis for a study starting in 1990 and finishing in 2000 and with a hypothetical data frame called `\mverb{mydata}' can be performed by typing the following command into R:
<<eval=FALSE>>=
out         <- basta(object = mydata, studyStart = 1990, studyEnd = 2000)
@

All other arguments have default values that allow to run the model without specifying any additional information (default values can be viewed on the \mverb{basta()} help file). Still, in order to make use of all the functionality of BaSTA we recommend to explore different models and shapes, as well as different covariate structures. Below we present how to set up an analysis with BaSTA to test a range of models and covariate data structures (further details on the models and diagnostics can be found in \citealt{BaSTA2011}) .

\subsection{Choosing mortality models: arguments \mverb{model} and \mverb{shape}}
Argument \mverb{model} can be used to choose between four basic mortality rate functions: a) `\mverb{EX}'; exponential (\citealt{Cox&Oakes1984}); b) `\mverb{GO}' (default); Gompertz (\citealt{Gompertz:1825,Pletcher1999}); c) `\mverb{WE}'; Weibull (\citealt{Pinder1978}); and d) `\mverb{LO}'; logistic (\citealt{Pletcher1999}) (Table \ref{Tabmod}). Each one of these functions can describe different trends in age-specific mortality, giving BaSTA considerable flexibility when estimating these vital rates (Fig. \ref{Fig2}). 
\begin{figure}[h!]
  \label{Fig2}
  \begin{center}
    \includegraphics[width=14cm]{Fig3}
  \caption{Mortality rates, $\mu(x | \theta)$, resulting from the four basic models included in BaSTA: a) exponential; b) Gompertz; c) Weibull; and d) logistic. The three different lines in each plot (except in a) show examples of the shapes that can be tested with BaSTA, namely: `simple'; `Makeham'; and `bathtub'.}
  \end{center}
\end{figure}

In addition, BaSTA allows to extend these basic functions to include more complex shapes. Specifically, three general forms can be defined with argument \mverb{shape}: i) `\mverb{simple}' (default), which uses only the basic functions defined in Table \ref{Tabmod}; ii) `\mverb{Makeham}' \citep{Pletcher1999}, which adds a constant to the mortality rate; and iii) `\mverb{bathtub}' (e.g. \citealt{Siler:1979}), which consists of adding a declining Gompertz function and a constant to the basic mortality rate. The resulting shapes can be seen in Fig. \ref{Fig2}.  In table \ref{Tabpars} we show the number of parameters for the different types of mortality models and shape combinations.

\begin{table}[h!]
  \caption{Number of parameters for all combinations of mortality models and shapes that can be tested in BaSTA.}
  \label{Tabpars}
  \begin{center}
\begin{tabular}{cccc}
\hline
\textbf{Model} & \textbf{simple} & \textbf{Makeham} & \textbf{bathtub} \\[0.1cm]
\hline\hline
&&&\\[-0.25cm]
Exponential & 1 & -- & -- \\
Gompertz   & 2 & 3 & 5 \\
Weibull   & 2 & 3 & 5 \\
Logistic   & 3 & 4 & 6 \\
\hline
\end{tabular}
  \end{center}
\end{table}

For instance, to run the analysis using a logistic mortality rate with a bathtub shape, the specifications for the function should be:

<<eval=FALSE>>=
out         <- basta(object = mydata, studyStart = 1990, studyEnd = 2000, model = "LO", shape = "bathtub")
@

In case the model or the shape are misspecified, the analysis is stopped and an error message is printed that clarifies which argument values should be used. 

\subsection{Defining covariate structure: argument \mverb{covarsStruct}}
BaSTA also allows to evaluate the effect of covariates on age patterns of mortality. This is achieved with argument \mverb{covarsStruct}, which defines three optional structures: i) `\mverb{fused}' (default), in which covariates are separated into continuous and categorical, where the first are included into a proportional hazards framework \citep{Klein:2003}, and the later are included as linear functions of the mortality parameters, analogous to generalized linear models (GLMs); ii) `\mverb{prop.haz}' where all covariates are included as proportional hazards; and iii) `\mverb{all.in.mort}' where all covariates are evaluated as linear functions of the mortality parameters. Currently, this last can only be implemented with Gompertz (`\mverb{GO}') model with `\mverb{simple}' shape. 

\subsection{MCMC general settings: \mverb{niter}, \mverb{burnin} and \mverb{thinning}}
The number of MCMC steps can be specified with argument \mverb{niter}, while the burn-in sequence and the thinning interval are controlled with arguments \mverb{burnin} and \mverb{thinning}, respectively. The burn-in corresponds to the initial sequence before parameters reach convergence, which is commonly discarded, leaving the remaining steps to calculate a range of diagnostics and other statistics \citep{Clark:2007}. The thinning interval is set as to reduce serial autocorrelation between consecutive parameter estimates. Based on the results from \cite{ColcheroClark2011}, the default values are \mverb{niter} $= 50,000$ steps, \mverb{burnin} $= 5,001$ and \mverb{thinning} $= 50$. Still, we recommend that these values should be tested before the final simulations are implemented.

\subsection{Initial parameters, jumps and priors}
Although BaSTA has built-in default values for initial parameters, jump standard deviations and priors, these can be modified with arguments \mverb{thetaStart} and \mverb{gammaStart} for mortality and proportional hazards initial parameters, and the corresponding \mverb{thetaJumps}, \mverb{thetaPriors}, \mverb{gammaJumps} and \mverb{gammaPriors} for jumps and priors. It is important to note that the length of the vector or the dimensions of the matrices specified should correspond to the number of parameters for each combination of \mverb{model}, \mverb{shape}, and \mverb{covarsStruct}. For instance, if a logistic (`\mverb{LO}') model with `\mverb{simple}' shape (i.e. 3 parameters, Table \ref{Tabpars}) and a `\mverb{mixed}' covariate structure is chosen, and two categorical and two continuous covariates are included in the dataset, \mverb{thetaStart}, \mverb{thetaJumps} and \mverb{thetaPriors} should be vectors of length 3 (the same set of parameters for both categorical covariates), or of length 6 (one set of parameters per covariate), or matrices of dimension $2 \times 3$. Also, \mverb{gammaStart}, \mverb{gammaJumps} and \mverb{gammaPriors} should all be vectors of length 2 for this example. For instance, if we wish to specify the jumps for the mortality parameters in this example, we could type:

<<eval=FALSE>>=
out         <- basta(object = mydata, studyStart = 1990, studyEnd = 2000, model = "LO", shape = "simple", thetaJumps = c(0.1, 0.1, 0.1))
@

\noindent or, alternatively we could create a matrix of jumps of the form:
<<>>=
new.jumps    <- matrix(c(rep(0.1, 3), rep(0.2, 3)), nrow = 2, ncol = 3, byrow = TRUE, dimnames = list(c('cov1', 'cov2'), paste("b", 0:2, sep="")))
@

\noindent where each column corresponds to a mortality parameter and each row to a covariate, of the form:
<<print=FALSE,echo=FALSE>>=
print(new.jumps)
@

\noindent which then we could use for the \mverb{thetaJumps} argument:
<<eval=FALSE>>=
out         <- basta(object = mydata, studyStart = 1990, studyEnd = 2000, model = "LO", shape = "simple", thetaJumps = new.jumps)
@

\subsection{Multiple runs: arguments \mverb{nsim}, \mverb{parallel} and \mverb{ncpus}}
To ensure that parameter estimates derived from MCMC routines converge appropriately, it is necessary to run several simulations from over-dispersed initial parameter values \citep{Gelman:2004}. By doing this, it is possible to confirm if the parameter chains (i.e. traces) all converge to the same final values, irrespective of the initial parameters. BaSTA allows to run multiple simulations by specifying the number of runs desired with argument \mverb{nsim}. Moreover, to reduce the amount of computing time, BaSTA facilitates to perform these multiple runs in parallel through package snowfall \citep{Knaus2010}. This is achieved by setting the logical argument \mverb{parallel} as `\mverb{TRUE}'. In addition, the number of cores used can be selected with argument \mverb{ncpus}. In case the package \mverb{snowfall} is not installed, or the argument \mverb{parallel} is set as `\mverb{FALSE}', then the multiple simulations are ran in series. We strongly recommend running multiple simulations in parallel, since this reduces computing time proportionally to the number of cpus used. Most computers today have dual or quad core processors, while many of them can handle hyper-threading (HT), which allows to split one core into two virtual processors. This means that, with the average lap-top with dual core and HT capabilities, one can potentially run up to 4 simulations in parallel.

Thus, to run 4 simulations in parallel on 4 cpus for a simple-shaped Gompertz model, function \mverb{basta()} can be specified as:
<<eval=FALSE>>=
out         <- basta(object = mydata, studyStart = 1990, studyEnd = 2000, nsim = 4, parallel = TRUE, ncpus = 4)
@


\section{Results}
\subsection{MCMC performance diagnostics}
After the MCMC algorithms are finished, a range of diagnostics are calculated on the parameter chains. 
If multiple simulations are implemented and all of them run through, then potential scale reduction is calculated for each parameter to estimate convergence \citep{Gelman:2004}. This diagnostic is calculated as $\hat{R} = \sqrt{\hat{v}^+ / W}$ , where $W$ is a measure of the within-sequence variance and $\hat{v}^+$ is a weighted average of the between-sequence variance ($B$) and $W$. Convergence is attained when $\hat{R}$ is close to 1. As a rule of thumb, we have assigned an arbitrary upper bound of $\hat{R}<1.1$ above which it is assumed that parameters have not reached convergence. 

\subsection{Model fit}
If all parameters have converged, BaSTA calculates deviance information criterion (DIC; \citealt{Spiegelhalter2002}), which has been described as a measure of predictive power and a criterion for model fit. DIC approximates the expected predictive deviance, and is calculated as 

\begin{equation*}
\mathrm{DIC} = 2\hat{D}_{avg}(y) - D_{\hat{\theta}}(y)
\end{equation*}

\noindent where $y$ denotes the observed data, $\hat{D}_{avg}(y)$ is the mean discrepancy between the data and the model as a function of the parameters $\theta$, averaged over the posterior distribution, while $D_{\hat{\theta}}(y)$ is the discrepancy at the posterior mode (here represented by the point estimate $\hat{\theta}$). It is important to outline that the use of DICs is still controversial and therefore the results need to be taken with caution (see responses in \citealt{Spiegelhalter2002}). In order to improve the measure provided, BaSTA's DIC is calculated as an approximation to the group-marginalized DIC presented by \citet{Millar2009}. 

\subsection{Parameter comparison for categorical covariates}
In addition, BaSTA includes a diagnostic based on Kullback-Liebler discrepancies (KLD; \citealt{KullbackLiebler1951,McCulloch1989}), that provides the user with a measure of how differently (or similarly) each categorical covariate affects survival.  For instance, if we wish to evaluate the differences in survival between males and females with a simple Gompertz model, such that the mortality rate is of the form:
\begin{equation}\label{eq:lin}
\mu(x | \bth) = \exp\left[\overbrace{\left(\bal^T z\right)}^{b_0} + \overbrace{\left(\bbe^T z\right)}^{b_1} x\right],
\end{equation}
where $\bth$ are mortality parameters such that $\bth = [b_0, b_1]$ and $\bal$ and $\bbe$ are subparameters that  then both parameters $b_0$ and $b_1$ in equation \ref{eq:lin} are evaluated as a function of these covariates. To illustrate this lets take $b_0$, for which the resulting `sub-parameters' would be $\alpha_{f}$ and $\alpha_{m}$ such that, for an individual $i$, we have $b_0 = \alpha_f I_i + \alpha_m (1 - I_i)$, where $I_i$ is an indicator function that assigns 1 if the individual is a female and 0 otherwise. For each of these parameters, BaSTA produces a posterior distribution, say $P_f = p(\alpha_{f} | \dots)$ and $P_m = p(\alpha_{m} | \dots)$, respectively. The KLD between these distributions is calculated as:

\begin{equation}\label{eq:kld}
K(P_f, P_m) = \int_{0}^{\infty} P_f \log\left(\frac{P_f}{P_m}\right) d\alpha
\end{equation}

The result can be interpreted as how far off we would be if we tried to predict $\alpha_m$ from the posterior distribution of $\alpha_f$. If both distributions are identical, then $K(P_f, P_m) = 0$, suggesting that there is no distinction between males and females for $b_0$; as the KLD values increase the higher the discrepancy becomes. As it can be inferred from equation \ref{eq:kld} the relationship is asymmetric, namely $K(P_f, P_m) \neq K(P_m, P_f)$. 

\citet{McCulloch1989} proposed a simple calibration of the KLD values that reduces the asymmetry and makes them easier to interpret. Let $k = K(P_f, P_m)$ and $q(k)$ a calibration function such that 
\begin{eqnarray*}
k & = & K(P_f,P_m) \\
&=&  K(B(1/2), B(q(k)))
\end{eqnarray*}

where $B(1/2)$ is a Bernouilli distribution for an event with probability $1/2$ (i.e. same probability of success and failure). This calibration is then calculated as:

\begin{equation}\label{eq:qk}
q(k) = (1 + (1 - e^{-2k})^{1/2})/2
\end{equation} 

Thus, $q(k)$ ranges from 0.5 to 1, where a value of 0.5 means that the distributions are identical, and 1 that there is no overlap between them.


\subsection{Model outputs}
The output provided by function \mverb{basta()} is a list object of class \mverb{basta} that includes a range of diagnostics and results. This list includes summarized results in the form of coefficients (with standard errors and credible intervals), MCMC performance diagnostics, model settings as specified by the user, estimations of model fit and parameter overlap for categorical covariates, the raw traces from all runs, summarized values for times of birth and death, the data used in the model, and additional outputs such as life tables for each categorical covariate calculated from the estimated ages at death (without including left-truncated individuals). 

\section{Summarizing and plotting results}
\subsection{Printing results: functions \mverb{print()} and \mverb{summary()}}
As we mentioned above, BaSTA's outputs can be explored using some of the R generic functions. For instance, functions \mverb{print()} and \mverb{summary()} print a range of summary statistics and descriptions of the model used. Basic summary values can be visualized by only typing the name of the BaSTA output object into the R console, while more information can be printed with function \mverb{summary}. For example, here are the summary values for a simple-shaped Gompertz analysis on the simulated dataset included in the package, with 4 parallel simulations: 

<<>>=
summary(basta.out, digits = 3)
@


\subsection{Plotting results: function \mverb{plot()}}
To visually verify that all parameter estimates have reached convergence, function \mverb{plot()} can be used on the BaSTA output object. Here is an example with the same output described above:
<<eval=FALSE>>=
plot(basta.out)
@
Which produces the following plot of traces for the mortality parameters:
\begin{center}
<<fig =TRUE , echo =FALSE >>=
plot(basta.out)
@
\end{center}
In this case, no additional arguments are required. To plot the traces of the proportional hazards or recapture probability parameters or of the posterior chains, argument \mverb{trace.name} should be specified, with values \mverb{gamma}, \mverb{pi} or \mverb{post}. For instance, here is the code to plot the traces of the proportional hazards parameters:
<<eval=FALSE>>=
plot(basta.out, trace.name = "gamma")
@

In addition, the predicted survival probabilities and mortality rate functions for the different categorical covariates can be plot by typing:
<<eval=FALSE>>=
plot(basta.out, plot.trace = FALSE)
@

Which produces the following plot:
\begin{center}
<<fig =TRUE , echo =FALSE >>=
plot(basta.out, plot.trace = FALSE)
@
\end{center}


%\section{Troubleshooting}
%\subsection{How to interpret serial autocorrelation and update rate values}
%\subsection{MCMC starts but does not finish for some simulations}
%\subsection{The traces seem to rarely update}
%\subsection{Serial autocorrelation is high but update rate is low}
%\subsection{Models with \mverb{bathtub} shape don't seem to converge}

\pagebreak
\renewcommand{\bibname}{References}
\let\oldbibsection\bibsection
\renewcommand{\bibsection}{\oldbibsection\addcontentsline{toc}{part}{References}}
\bibliographystyle{jae}
\bibliography{Refs}

\newpage
\section{Additional information}
\subsection{Mortality model details}

\begin{table}[h!]
  \caption{Mortality rates for all models included in BaSTA.}
  \label{Tabmod}
  \begin{center}
\begin{tabular}{cccc}
\hline
\multirow{2}{*}{\textbf{Function}} & \textbf{Mortality rate} & \textbf{Survival probability} & \multirow{2}{*}{\textbf{Parameters}}\\
& $\mu_b(x | \mathbf{b})$ & $S_b(x | \mathbf{b})$&\\
\hline\hline
&&&\\[-0.25cm]
Exponential & $b$ & $ e^{-b x}$ & $b > 0$\\[0.5cm]
Gompertz   &$e^{b_0 + b_1 x}$&$\exp\left[\frac{e^{b_0}}{b_1} (1 - e^{b_1 x})\right]$ &$-\infty < b_0, b_1 < \infty$\\[0.5cm]
Weibull   &$b_0 b_1^{b_0} x^{b_0 -1}$&$\exp\left[-(b_1 x)^{b_0}\right]$ &$b_0, b_1 > 0$\\[0.5cm]
Logistic   &$\frac{e^{b_0 + b_1 x}}{1+b_2 \frac{e^{b_0}}{b_1} (e^{b_1 x}-1)}$&$\left(1 + b_2 \frac{e^{b_0}}{b_1} \left(e^{b_1 x} - 1\right)\right)^{-1 / b_2}$&$b_0, b_1, b_2 > 0$\\[0.5cm]
\hline
\end{tabular}
  \end{center}
\end{table}




\end{document}